This is a theoretical scenario designed to illustrate the false-positive problem associated with detecting rare diseases.<br>
<br>
<br>
Pretend that we're testing for a disease.  Our disease test is 99.5% accurate, and the disease infects 0.5% of people.  This is similar to the current AIDS accuracy and prevalence in America.<br>
<br>
This means that 0.5% of the people who have the disease will be falsely tested negative, and 0.5% of the people who don't have the disease will be falsely tested positive.<br>
<br>
0.5% * 99.5% = 0.4975% of the population is tested falsely positive.<br>
0.5% * 0.5% = 0.0025% of the population is tested falsely negative.<br>
<br>
All figures are in percent of total population.<br>
<table>
<tr><th></th><th>Has disease</th><th>Doesn't have it</th></tr>
<tr><th>Actual</th><td>0.5%</td><td>99.5%</td></tr>
<tr><th>Tests positive</th><td>0.4975%</td><td>0.4975%</td></tr>
<tr><th>Tests negative</th><td>0.0025%</td><td>99.0025%</td></tr>
</table>
<br>
This means that 0.4975% of the population has the disease and tests positive for it, and that 0.4975% of the population <b>doesn't</b> have the disease and tests positive for it.<br>
So, half of the patients that test positive don't have the disease, despite our test being 99.5% accurate.<br>
<br>
In order to combat this problem, after someone is tested positive for AIDS, they are given what's called a "confirmatory" test.  This brings the accuracy of the overall check much closer to 100%.<br>
<a href="http://www.redcross.org/services/hss/tips/goodtest.html">http://www.redcross.org/services/hss/tips/goodtest.html</a>
